{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "import pgeocode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect('home_sales.db')\n",
    "df = pd.read_sql_query('SELECT * FROM sales;',db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping null values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering place_name from zipcode\n",
    "nomi = pgeocode.Nominatim('us')\n",
    "for index, row in df.iterrows():\n",
    "    locObj = nomi.query_postal_code(int(row['zipcode']))\n",
    "    df.loc[index,'place_name'] = locObj.place_name\n",
    "df = df.replace({'place_name': {'Auburn':1,'Federal Way':2,'Kent':3,'Enumclaw':4,'Maple Valley':5,'Renton':6,'Black Diamond':7,'North Bend':8,'Duvall':9,'Carnation':10,'Kenmore':11,'Seattle':12,'Fall City':13,'Bothell':14,'Vashon':15,'Snoqualmie':16,'Kirkland':17,'Issaquah':18,'Woodinville':19,'Redmond':20,'Sammamish':21,'Bellevue':22,'Mercer Island':23,'Medina':24}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relabel condition feature\n",
    "df.loc[df.condition == 'TERRIBLE'] = df.loc[df.condition == 'TERRIBLE'].replace(\"TERRIBLE\",\"0\")\n",
    "df.loc[df.condition == 'terrible'] = df.loc[df.condition == 'terrible'].replace(\"terrible\",\"0\")\n",
    "df.loc[df.condition == 'POOR'] = df.loc[df.condition == 'POOR'].replace(\"POOR\",\"1\")\n",
    "df.loc[df.condition == 'poor'] = df.loc[df.condition == 'poor'].replace(\"poor\",\"1\")\n",
    "df.loc[df.condition == 'FAIR'] = df.loc[df.condition == 'FAIR'].replace(\"FAIR\",\"2\")\n",
    "df.loc[df.condition == 'fair'] = df.loc[df.condition == 'fair'].replace(\"fair\",\"2\")\n",
    "df.loc[df.condition == 'GOOD'] = df.loc[df.condition == 'GOOD'].replace(\"GOOD\",\"3\")\n",
    "df.loc[df.condition == 'good'] = df.loc[df.condition == 'good'].replace(\"good\",\"3\")\n",
    "df.loc[df.condition == 'EXCELLENT'] = df.loc[df.condition == 'EXCELLENT'].replace(\"EXCELLENT\",\"4\")\n",
    "df.loc[df.condition == 'excellent'] = df.loc[df.condition == 'excellent'].replace(\"excellent\",\"4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert object to int\n",
    "df['condition'] = df['condition'].astype(str).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping unnecessary features\n",
    "df = df[['price', 'bedrooms', 'bathrooms', 'floors', 'waterfront', 'view', 'condition','review_score', 'basement_size', 'built', 'renovation','living_room_size', 'lot_size','place_name','latitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transform housing price\n",
    "df['log_price'] = np.log1p(df['price'])\n",
    "df = df.drop(columns=['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate dataset into X and y\n",
    "y = df['log_price']\n",
    "df = df.drop(columns=['log_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transform on X dataset for features with skewness >0.5\n",
    "skewness = df.apply(lambda x: skew(x))\n",
    "skewness = skewness[abs(skewness) > 0.5]\n",
    "skewed_features = skewness.index\n",
    "df[skewed_features] = np.log1p(df[skewed_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition the dataset in train + test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size = 0.5, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform features by standardization\n",
    "# stdSc = StandardScaler()\n",
    "# X_train = stdSc.fit_transform(X_train)\n",
    "# X_test = stdSc.transform(X_test)\n",
    "# Standardization has no effect on prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for RMSE evaluation metrics with KFold CV\n",
    "from sklearn.model_selection import KFold\n",
    "n_folds = 5\n",
    "def rmse_CV_train(model):\n",
    "    kf = KFold(n_folds,shuffle=True,random_state=42).get_n_splits(X_train)\n",
    "    rmse = np.sqrt(-cross_val_score(model,X_train,y_train,scoring =\"neg_mean_squared_error\",cv=kf))\n",
    "    return rmse\n",
    "def rmse_CV_test(model):\n",
    "    kf = KFold(n_folds,shuffle=True,random_state=42).get_n_splits(X_test)\n",
    "    rmse = np.sqrt(-cross_val_score(model,X_test,np.exp(y_test),scoring =\"neg_mean_squared_error\",cv=kf))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse on train 0.2829659844570017\n",
      "rmse on test 236223.57554988976\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "test_pre = lr.predict(X_test)\n",
    "train_pre = lr.predict(X_train)\n",
    "print('rmse on train',rmse_CV_train(lr).mean())\n",
    "print('rmse on test',rmse_CV_test(lr).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot between predicted values and residuals\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.scatter(train_pre, train_pre - y_train, c = \"blue\",  label = \"Training data\")\n",
    "# plt.scatter(test_pre,test_pre - y_test, c = \"black\",  label = \"Validation data\")\n",
    "# plt.title(\"Linear regression\")\n",
    "# plt.xlabel(\"Predicted values\")\n",
    "# plt.ylabel(\"Residuals\")\n",
    "# plt.legend(loc = \"upper left\")\n",
    "# plt.hlines(y = 0, xmin = 10.5, xmax = 13.5, color = \"red\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions - Real values\n",
    "# plt.scatter(train_pre, y_train, c = \"blue\",  label = \"Training data\")\n",
    "# plt.scatter(test_pre, y_test, c = \"black\",  label = \"Validation data\")\n",
    "# plt.title(\"Linear regression\")\n",
    "# plt.xlabel(\"Predicted values\")\n",
    "# plt.ylabel(\"Real values\")\n",
    "# plt.legend(loc = \"upper left\")\n",
    "# plt.plot([10.5, 13.5], [10.5, 13.5], c = \"red\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVR\n",
    "# svr_lin = SVR(kernel='linear', C=100, gamma='auto')\n",
    "# svr_lin.fit(X_train,y_train)\n",
    "# test_pre = svr_lin.predict(X_test)\n",
    "# train_pre = svr_lin.predict(X_train)\n",
    "# print('rmse on train',rmse_CV_train(svr_lin).mean())\n",
    "# print('rmse on test',rmse_CV_test(svr_lin).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plot between predicted values and residuals\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.scatter(train_pre, train_pre - y_train, c = \"blue\",  label = \"Training data\")\n",
    "# plt.scatter(test_pre,test_pre - y_test, c = \"black\",  label = \"Validation data\")\n",
    "# plt.title(\"Linear regression\")\n",
    "# plt.xlabel(\"Predicted values\")\n",
    "# plt.ylabel(\"Residuals\")\n",
    "# plt.legend(loc = \"upper left\")\n",
    "# plt.hlines(y = 0, xmin = 10.5, xmax = 13.5, color = \"red\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot predictions - Real values\n",
    "# plt.scatter(train_pre, y_train, c = \"blue\",  label = \"Training data\")\n",
    "# plt.scatter(test_pre, y_test, c = \"black\",  label = \"Validation data\")\n",
    "# plt.title(\"Linear regression\")\n",
    "# plt.xlabel(\"Predicted values\")\n",
    "# plt.ylabel(\"Real values\")\n",
    "# plt.legend(loc = \"upper left\")\n",
    "# plt.plot([10.5, 13.5], [10.5, 13.5], c = \"red\")\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
